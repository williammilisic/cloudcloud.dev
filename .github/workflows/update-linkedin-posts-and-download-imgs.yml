name: Update LinkedIn Posts and Download Images
on:
  schedule:
    - cron: "0 0 * * 1" # Runs every Monday at midnight UTC
  workflow_dispatch:

jobs:
  update-linkedin-posts:
    runs-on: ubuntu-latest
    steps:
      - name: Check out repository
        uses: actions/checkout@v3

      - name: Install jq
        run: sudo apt-get update && sudo apt-get install -y jq

      - name: Fetch LinkedIn posts
        env:
          RAPIDAPI_LINKEDIN_DATA_API_KEY: ${{ secrets.RAPIDAPI_LINKEDIN_DATA_API_KEY }}
        run: |
          # Generate URL-encoded date string for last week's UTC date at 00:00
          encodedDate=$(date -u -d '7 days ago' +'%Y-%m-%d 00:00' | sed 's/ /%20/g;s/:/%3A/g')
          echo "Fetching posts from date: $encodedDate"
          # Fetch LinkedIn posts using the API
posts_file="linkedin-posts.json"
username="williammilisic"
api_url="https://linkedin-scraper-api-real-time-fast-affordable.p.rapidapi.com/profile/posts"
api_host="linkedin-scraper-api-real-time-fast-affordable.p.rapidapi.com"
api_key="${{ secrets.RAPIDAPI_LINKEDIN_DATA_API_KEY }}"

all_posts=()
pagination_token=""

while :; do
    if [ -z "$pagination_token" ]; then
        response=$(curl --silent --request GET \
            --url "$api_url?username=$username" \
            --header "x-rapidapi-host: $api_host" \
            --header "x-rapidapi-key: $api_key")
    else
        response=$(curl --silent --request GET \
            --url "$api_url?username=$username&paginationToken=$pagination_token" \
            --header "x-rapidapi-host: $api_host" \
            --header "x-rapidapi-key: $api_key")
    fi

    # Extract posts and append to collection
    page_posts=$(echo "$response" | jq '.data.posts')
    all_posts+=( $(echo "$page_posts") )

    # Get next pagination token, if any
    pagination_token=$(echo "$response" | jq -r '.paginationToken // empty')

    # Stop if no more pages
    [ -z "$pagination_token" ] && break
done

# Combine posts into one big JSON output file
jq -n --argjson posts "$(printf '%s\n' "${all_posts[@]}" | jq -s 'add')" \
   '{success: true, message: "", data: {posts: $posts}}' > "$posts_file"


      - name: Merge new posts with existing JSON
        run: |
          # If the JSON file already exists, merge new data with the existing entries.
          if [ -f _data/linkedin-posts.json ]; then
            # count existing posts
            originalCount=$(jq '.data.posts | length' _data/linkedin-posts.json)
            # merge posts arrays using posted_at.timestamp
          jq -s '{
              success: true,
              message: "",
              data: {
                posts: (.[0].data.posts + .[1].data.posts
                        | unique_by(.posted_at.timestamp)
                        | sort_by(.posted_at.timestamp)
                        | reverse
                        | map(
                            .commentsCount = (.stats.comments | tonumber)
                          | .totalReactionCount = (.stats.total_reactions | tonumber)
                          | .repostsCount = (.stats.reposts | tonumber)
                         )
                       )
              }
            }' linkedin-posts.json _data/linkedin-posts.json > merged.json
            newCount=$(jq '.data.posts | length' merged.json)
            echo "Number of new entries added: $((newCount - originalCount))"
          else
            # initialize new feed sorted by timestamp
          jq '{
              success: true,
              message: "",
              data: {
                posts: (.data.posts
                        | sort_by(.posted_at.timestamp)
                        | reverse
                        | map(
                            .commentsCount = (.stats.comments | tonumber)
                          | .totalReactionCount = (.stats.total_reactions | tonumber)
                          | .repostsCount = (.stats.reposts | tonumber)
                         )
                       )
              }
            }' linkedin-posts.json > merged.json
            newCount=$(jq '.data.posts | length' merged.json)
            echo "Number of new entries added: $newCount"
          fi
          # Move the merged file to the _data directory, overwriting if it exists
          mv -f merged.json _data/linkedin-posts.json

      - name: Remove temporary posts file
        run: rm -f linkedin-posts.json

      - name: Commit and push changes if any
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"
          git add _data/linkedin-posts.json
          git add assets/images/linkedin/
          if [ -n "$(git status --porcelain)" ]; then
            git commit -m "Update LinkedIn posts and images $(date -u +'%Y-%m-%d')"
            git push
          else
            echo "No changes to commit"
          fi
