name: Update LinkedIn Posts and Download Images

on:
  schedule:
    - cron: "0 0 * * 1" # Every Monday at midnight UTC
  workflow_dispatch:

jobs:
  update-linkedin-posts:
    runs-on: ubuntu-latest
    steps:
      - name: Check out repository
        uses: actions/checkout@v3

      - name: Install jq
        run: sudo apt-get update && sudo apt-get install -y jq

      - name: Fetch ALL LinkedIn posts with pagination
        env:
          RAPIDAPI_LINKEDIN_DATA_API_KEY: ${{ secrets.RAPIDAPI_LINKEDIN_DATA_API_KEY }}
        run: |
          posts_file="linkedin-posts.json"
          username="williammilisic"
          api_url="https://linkedin-scraper-api-real-time-fast-affordable.p.rapidapi.com/profile/posts"
          api_host="linkedin-scraper-api-real-time-fast-affordable.p.rapidapi.com"
          api_key="${RAPIDAPI_LINKEDIN_DATA_API_KEY}"

          tmp_posts="tmp_posts.jsonl"
          : > "$tmp_posts"

          pagination_token=""
          while :; do
            if [ -z "$pagination_token" ]; then
              response=$(curl --silent --request GET \
                --url "$api_url?username=$username" \
                --header "x-rapidapi-host: $api_host" \
                --header "x-rapidapi-key: $api_key")
            else
              response=$(curl --silent --request GET \
                --url "$api_url?username=$username&paginationToken=$pagination_token" \
                --header "x-rapidapi-host: $api_host" \
                --header "x-rapidapi-key: $api_key")
            fi

            echo "$response" | jq -c '.data.posts[]?' >> "$tmp_posts"
            pagination_token=$(echo "$response" | jq -r '.paginationToken // empty')
            [ -z "$pagination_token" ] && break
          done

          jq -s '{success: true, message: "", data: {posts: .}}' "$tmp_posts" > "$posts_file"
          rm -f "$tmp_posts"

      - name: Merge new posts with existing JSON
        run: |
          if [ -f _data/linkedin-posts.json ]; then
            originalCount=$(jq '.data.posts | length' _data/linkedin-posts.json)
            jq -s '
            {
              success: true,
              message: "",
              data: {
                posts: (.[0].data.posts + .[1].data.posts
                  | unique_by(.posted_at.timestamp)
                  | sort_by(.posted_at.timestamp)
                  | reverse
                  | map(
                      .commentsCount = (.stats.comments | tonumber)
                      | .totalReactionCount = (.stats.total_reactions | tonumber)
                      | .repostsCount = (.stats.reposts | tonumber)
                    )
                )
              }
            }' linkedin-posts.json _data/linkedin-posts.json > merged.json
            newCount=$(jq '.data.posts | length' merged.json)
            echo "Number of new entries added: $((newCount - originalCount))"
          else
            jq '
            {
              success: true,
              message: "",
              data: {
                posts: (.data.posts
                  | sort_by(.posted_at.timestamp)
                  | reverse
                  | map(
                      .commentsCount = (.stats.comments | tonumber)
                      | .totalReactionCount = (.stats.total_reactions | tonumber)
                      | .repostsCount = (.stats.reposts | tonumber)
                    )
                )
              }
            }' linkedin-posts.json > merged.json
            newCount=$(jq '.data.posts | length' merged.json)
            echo "Number of new entries added: $newCount"
          fi
          mv -f merged.json _data/linkedin-posts.json

      - name: Remove temporary posts file
        run: rm -f linkedin
